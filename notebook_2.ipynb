{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CaRlRd3_Ba1"
      },
      "source": [
        "# Título: Automatización de Soporte TI con Gemini Vision y Trello\n",
        "\n",
        "## Objetivo:\n",
        "Desarrollar una solución automatizada que utilice videos de problemas reportados por usuarios para crear, resumir, etiquetar y gestionar tarjetas en Trello de manera automática, aprovechando las capacidades de Gemini Pro Vision.\n",
        "\n",
        "## Instrucciones:\n",
        "Sigue los pasos detallados en este notebook para configurar el entorno, autenticarte en Google Cloud Platform, procesar videos con modelos de IA generativa, y finalmente, interactuar con la API de Trello para gestionar tickets de soporte."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-BfX1Fz_Ba2"
      },
      "source": [
        "### Instalamos dependencias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OXCvRwUP_Ba2"
      },
      "outputs": [],
      "source": [
        "# Instalamos el cliente de Python para Vertex AI\n",
        "!pip install google-api-python-client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4EvYdXOC_Ba2"
      },
      "outputs": [],
      "source": [
        "# Instalamos paquetes para conectarnos a los servicios de Google\n",
        "!pip install google-auth\n",
        "!pip install google-auth-oauthlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "EVvbzYCg_Ba2"
      },
      "outputs": [],
      "source": [
        "# Instalamos Vertex AI (Plataforma de desarrollo de soluciones de AI Generativa).\n",
        "# Con esta plataforma podremos acceder a los differentes modelos de Gemini de Google y a otros servicios de Agentes y Chat.\n",
        "!pip install vertexai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "XgAaZSjD_Ba2"
      },
      "outputs": [],
      "source": [
        "# Instala Vertex Search\n",
        "!pip install --upgrade --quiet google-cloud-discoveryengine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "T9gvLs6r_5Kw"
      },
      "outputs": [],
      "source": [
        "# Instalamos LangChain y las dependencias de Google Vertex\n",
        "!pip install langchain-google-vertexai\n",
        "!pip install langchain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PU0ePv4-_Ba3"
      },
      "source": [
        "### Nos autenticamos para acceder a Google Cloud."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "VCGaYJkfB2NU"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pd_eLYb1_Ba3"
      },
      "source": [
        "Importamos Vertex AI, y desde Vertex AI obtenemos los constructores de las clases GenerativeModel y Part, que nos permitiran interactuar fácilmente con la API y diferentes tipos de formatos con los que podremos interactuar con el modelo (Texto, Imágenes, Audio, etc.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "CCmTWyLfv2Da"
      },
      "outputs": [],
      "source": [
        "import vertexai\n",
        "from vertexai.generative_models import GenerativeModel, Part"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "woUkyo2yv2Da"
      },
      "source": [
        "Cargamos el video de ejemplo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UDVuphxDv2Da"
      },
      "outputs": [],
      "source": [
        "import IPython\n",
        "\n",
        "video_url = \"https://storage.googleapis.com/workshop-bucket-elgueta-2024/Screen%20Recording%202024-04-26%20at%2014.35.40.mov\"\n",
        "\n",
        "\n",
        "IPython.display.Video(video_url, width=450)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JeUE1xbb_Ba3"
      },
      "source": [
        "Ten cuidado de indicar el project_id correcto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V533Xvzn_Ba3"
      },
      "outputs": [],
      "source": [
        "def generate_video_description(project_id, location, model_name, video_file_uri, prompt):\n",
        "    vertexai.init(project=project_id, location=location)\n",
        "\n",
        "    model = GenerativeModel(model_name)\n",
        "\n",
        "    video_file = Part.from_uri(video_file_uri, mime_type=\"video/mov\")\n",
        "\n",
        "    contents = [video_file, prompt]\n",
        "\n",
        "    response = model.generate_content(contents)\n",
        "    return response.text\n",
        "\n",
        "# Configuramos los parametros de la API para que funcione con nuestro proyecto de Google Cloud\n",
        "project_id = \"prj-uc-genai-labs\"\n",
        "location = \"us-central1\"\n",
        "\n",
        "# Configuramos los parametros del modelo y el tipo de input que le entregarémos.\n",
        "model_name = \"gemini-1.5-pro-preview-0409\"\n",
        "video_file_uri = \"gs://workshop-bucket-elgueta-2024/Screen Recording 2024-04-26 at 14.35.40.mov\"\n",
        "\n",
        "prompt = \"\"\"\n",
        "  Provide a description of the video.\n",
        "  The description should also contain anything important which people say in the video.\n",
        "  Output a json with this schema:\n",
        "  {\n",
        "    \"description\": \"The description of the problem the user is facing\",\n",
        "    }\n",
        "\"\"\"\n",
        "\n",
        "description = generate_video_description(project_id, location, model_name, video_file_uri, prompt)\n",
        "\n",
        "# Pequeño Debug para ver que nos está devolviendo la API\n",
        "print(description)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdQzuPpa_Ba3"
      },
      "source": [
        "## Integración con Trello para function calling\n",
        "Con la configuración completa de Google Cloud, Vertex AI, y los parámetros del modelo, nuestro siguiente paso es integrar la API de Trello para permitir que Gemini administre tickets. Los pasos a seguir son:\n",
        "#\n",
        "1. Registrarse en Trello visitando https://www.trello.com.\n",
        "2. Crear un Power-Up en Trello, que actuará como un puente entre nuestro tablero de Trello y su API.\n",
        "3. Obtener y guardar la API Key y el Token de Trello para permitir la interacción con la plataforma sin necesidad de usar credenciales directas.\n",
        "4. Localizar el idList de nuestro tablero de Trello siguiendo las instrucciones disponibles en: [Cómo encontrar el idList de un tablero](https://docs.n8n.io/integrations/builtin/app-nodes/n8n-nodes-base.trello/#how-do-i-find-the-list-id).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "7V25KDMtCd7K"
      },
      "outputs": [],
      "source": [
        "trello_id_list = \"tu-trello-id-list\"\n",
        "trello_api_key = \"tu-trello-api-key\"\n",
        "trello_token =  \"tu-trello-token\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VV6QlrJv2Db"
      },
      "source": [
        "Primero definimos la función que nos permitirá crear una tarjeta en Trello."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "R2SVA1Zs_Ba4"
      },
      "outputs": [],
      "source": [
        "# Esta función crea una tarjeta en Trello utilizando la API de Trello.\n",
        "def create_trello_card(name, due, start):\n",
        "    # Importamos los módulos necesarios para realizar la solicitud HTTP y manejar el formato JSON.\n",
        "    import requests\n",
        "    import json\n",
        "\n",
        "    # URL de la API de Trello para crear una nueva tarjeta.\n",
        "    url = \"https://api.trello.com/1/cards\"\n",
        "\n",
        "    # Definimos los headers de la solicitud, especificando que esperamos una respuesta en formato JSON.\n",
        "    headers = {\"Accept\": \"application/json\"}\n",
        "\n",
        "    # Parámetros de la solicitud, incluyendo el ID de la lista de Trello, la API key, el token, y los datos de la tarjeta.\n",
        "    query = {\n",
        "        \"idList\": trello_id_list,  # ID de la lista en Trello donde se creará la tarjeta.\n",
        "        \"key\": trello_api_key,     # Clave de la API de Trello.\n",
        "        \"token\": trello_token,     # Token de acceso a la API de Trello.\n",
        "        \"name\": name,              # Nombre de la tarjeta.\n",
        "        \"due\": due,                # Fecha de vencimiento de la tarjeta.\n",
        "        \"start\": start,            # Fecha de inicio de la tarjeta (no siempre es soportado por Trello).\n",
        "    }\n",
        "\n",
        "    # Realizamos la solicitud POST a la API de Trello para crear la tarjeta.\n",
        "    response = requests.request(\"POST\", url, headers=headers, params=query)\n",
        "\n",
        "    # Imprimimos la respuesta de la API de Trello, formateada en JSON para una mejor lectura.\n",
        "    print(\n",
        "        json.dumps(\n",
        "            json.loads(response.text), sort_keys=True, indent=4, separators=(\",\", \": \")\n",
        "        )\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYo4Dkk0DfnM"
      },
      "source": [
        "## Creando el Search App para hacer RAG\n",
        "\n",
        "En este paso, insertaremos un dataset que incluya la documentación de LangChain en Vertex Search, la cual los vectorizará por nosotros e insertará en la base de datos de vectores, a través de la cual podremos hacer búsqueda semántica.\n",
        "\n",
        "1.   Descargamos el dataset en formato json desde [aquí](https://huggingface.co/datasets/LangChainDatasets/langchain-howto-queries).\n",
        "2.   Seguimos estas [instrucciones](https://cloud.google.com/generative-ai-app-builder/docs/try-enterprise-search#create_and_preview_a_search_app_for_structured_data_from) para crear una Search App.\n",
        "3. Creamos la función para poder hacer búsquedas con Vertex Search.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "uQCKaojH_Ba4"
      },
      "outputs": [],
      "source": [
        "from langchain_community.retrievers import (\n",
        "    GoogleVertexAISearchRetriever,\n",
        ")\n",
        "# Definimos el ID del almacén de datos donde se realizará la búsqueda\n",
        "data_store_id = \"tu-data-store-id\"\n",
        "\n",
        "# Función para recuperar información de una búsqueda utilizando Vertex AI Search\n",
        "def retrieve_from_search(query):\n",
        "    # Definimos el ID del proyecto en Google Cloud\n",
        "    PROJECT_ID = project_id\n",
        "    # Definimos la ubicación del almacén de datos\n",
        "    LOCATION_ID = \"global\"\n",
        "    # Definimos el ID del almacén de datos\n",
        "    DATA_STORE_ID = data_store_id\n",
        "    # Creamos una instancia del retriever de Vertex AI Search con los parámetros definidos\n",
        "    retriever = GoogleVertexAISearchRetriever(\n",
        "        project_id=PROJECT_ID,\n",
        "        location_id=LOCATION_ID,\n",
        "        data_store_id=DATA_STORE_ID,\n",
        "        max_documents=3,  # Número máximo de documentos a recuperar\n",
        "        engine_data_type=1,  # Tipo de datos del motor de búsqueda\n",
        "    )\n",
        "    # Invocamos el retriever con la consulta proporcionada y almacenamos el resultado\n",
        "    result = retriever.invoke(query)\n",
        "    # Devolvemos el resultado de la búsqueda\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YyKde8tO_Ba4"
      },
      "source": [
        "Creamos un modelo Pydantic para nuestras funciones, lo que facilitará que LangChain comprenda la estructura de dichas funciones, y se las entregue a Gemini.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "uZOu3wVA_Ba4"
      },
      "outputs": [],
      "source": [
        "from pydantic import BaseModel, Field\n",
        "from typing import Optional\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "class CreateTrelloCardandAnswer(BaseModel):\n",
        "    \"\"\"\n",
        "    Function that calls the Trello API to create a new card.\n",
        "\n",
        "    \"\"\"\n",
        "    name: str = Field(..., description=\"Short description of the user problem\")\n",
        "    due: Optional[datetime] = Field(...,description=\"Name of the card\")\n",
        "    start: Optional[datetime] = Field(...,description=\"Name of the card\")\n",
        "    query: str = Field(..., description=\"Query to search\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_T4VI64_Ba4"
      },
      "source": [
        "Haremos un segundo llamado al LLM, para que en base a la descripción del video, extraiga los argumentos de nuestras funciones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "1sLOjdK4_Ba4"
      },
      "outputs": [],
      "source": [
        "# Importamos la integración de LangChain con Vertex AI\n",
        "from langchain_google_vertexai import ChatVertexAI\n",
        "from langchain_core.prompts import ChatPromptTemplate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHJRQf3hv2Dc"
      },
      "source": [
        "Convertimos la funciób CreateTrelloCardandAnswer a una herramienta de LangChain, y luego hacemos un llamado a Gemini, que usando function calling, nos devolverá un json que indicará que herramientas deben usarse."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-gl_lp6T_Ba4"
      },
      "outputs": [],
      "source": [
        "initial_prompt = \"\"\"\n",
        "Output json. Call the Trello Tool to create a new ticket and the RetrieveSearch to find the answer.\n",
        "User input: {input}\n",
        "\"\"\"\n",
        "tools = [CreateTrelloCardandAnswer]\n",
        "llm = ChatVertexAI(\n",
        "    model=\"gemini-1.5-pro-preview-0409\",\n",
        "    project_id=\"tu-project-id\",\n",
        "    location=\"us-central1\",\n",
        ")\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(initial_prompt)\n",
        "\n",
        "llm_with_tools = llm.bind_tools(tools)\n",
        "chain = prompt | llm_with_tools\n",
        "\n",
        "result = chain.invoke({\"input\": description})\n",
        "\n",
        "print(result.additional_kwargs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_WNWJn3v2Dd"
      },
      "source": [
        "Una vez obtenemos el resultado, debemos parsearlo para obtener el nombre y argumentos de las funciones que debe ser llamadas. Una vez obtenido esto, llamamos a la función, que hará 2 cosas;\n",
        "1. Crear el ticket en Trello.\n",
        "2. Buscar en Vertex Search la documentación apropiada para contestarle al usuario."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BxOC00R9_Ba4"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages.base import message_to_dict\n",
        "import json\n",
        "\n",
        "response_dict = message_to_dict(result)\n",
        "function_call = response_dict.get(\"data\", {}).get(\"additional_kwargs\", {}).get(\"function_call\", {})\n",
        "\n",
        "\n",
        "# Assuming 'arguments' is a JSON string, we need to parse it\n",
        "arguments_str = function_call.get(\"arguments\", \"{}\")  # Default to empty JSON object if not found\n",
        "try:\n",
        "    arguments = json.loads(arguments_str)  # Attempt to parse the string as JSON\n",
        "except json.JSONDecodeError:\n",
        "    arguments = {}  # If parsing fails, default to an empty dictionary\n",
        "\n",
        "\n",
        "if function_call.get(\"name\") == \"CreateTrelloCardandAnswer\":\n",
        "    print(type(arguments))  # This should now be 'dict' if the JSON was parsed successfully\n",
        "    create_trello_card(\n",
        "        name=arguments.get(\"name\"),\n",
        "        due=arguments.get(\"due\"),\n",
        "        start=arguments.get(\"start\"),\n",
        "    )\n",
        "    answer = retrieve_from_search(arguments.get(\"query\"))\n",
        "\n",
        "print(answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ltIvs8Av2Dd"
      },
      "source": [
        "Ahora con la respuestas de Vertex Search, podemos hacer un último llamado a Gemini, adjuntando la documentación en el prompt, para que le conteste al usuario y resuelva su problema."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZjjhfXmg_Ba4"
      },
      "outputs": [],
      "source": [
        "initial_prompt = \"\"\"\n",
        "Based on the user input, and the content retrieved from the search engine, output a response that resolves the user problem.\n",
        "User input: {input}\n",
        "Search result: {search_result}\n",
        "\"\"\"\n",
        "llm = ChatVertexAI(\n",
        "    model=\"gemini-1.5-pro-preview-0409\",\n",
        "    project_id=\"prj-uc-genai-labs\",\n",
        "    location=\"us-central1\",\n",
        ")\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(initial_prompt)\n",
        "\n",
        "chain = prompt | llm\n",
        "\n",
        "result = chain.invoke({\"input\": description, \"search_result\": answer})\n",
        "\n",
        "message_to_dict(result)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}