{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook 1: Trabajas en una compañía en el departamento de soporte TI. Ya llevas varios años y te das cuenta de que el trabajo es repetitivo y los usuarios suelen cometer los mismo errores. Con el tiempo el trabajo se va volviendo muy fácil y estás buscando como hacerlo más interesante de acuerdo a tus habilidades.\n",
    "\n",
    "Has pensado en utilizar tus conocimientos avanzados en Python y las sofisticadas herrarmientas de Inteligencia Artifical de Google para automatizar tu trabajo! En especial la plataforma de tickets (Trello).\n",
    "\n",
    "Objetivo: Crear una solución que tome los videos de los problemas de los usuarios, cree, resuma, etiquete y gestione targetas en Trello (Herramienta de tickets de desarrollo y soporte) automáticamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instalamos dependencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podemos explicar para que se instala esto?\n",
    "!pip install google-api-python-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalamos paquetes para conectarnos a los servicios de Google\n",
    "!pip install google-auth\n",
    "!pip install google-auth-oauthlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalamos Vertex AI (Plataforma de desarrollo de soluciones de AI Generativa).\n",
    "# Con esta plataforma podremos acceder a los differentes modelos de Gemini de Google y a otros servicios de Agentes y Chat.\n",
    "!pip install vertexai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalarémos un paquete para que Langchain interactue con Google Vertex AI\n",
    "!pip install langchain-core\n",
    "!pip install -qU langchain-google-vertexai\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mencionar de donde se saca la service account y su paso a paso\n",
    "Importamos las librerías de Google que instalamos previamente, y configuramos las credenciales de Google para autenticarnos con Google Cloud Platform a través de una cuenta de servicio.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.oauth2 import service_account\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "# Path to your service account key file\n",
    "SERVICE_ACCOUNT_FILE = \"prj-uc-genai-labs-8859d31dca67.json\"\n",
    "\n",
    "# Define the scopes\n",
    "SCOPES = [\"https://www.googleapis.com/auth/cloud-platform\"]\n",
    "\n",
    "# Authenticate and construct service\n",
    "credentials = service_account.Credentials.from_service_account_file(\n",
    "        SERVICE_ACCOUNT_FILE, scopes=SCOPES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos Vertex AI, y desde Vertex AI obtenemos los constructores de las clases GenerativeModel y Part, que nos permitiran interactuar fácilmente con la API y diferentes tipos de formatos con los que podremos interactuar con el modelo (Texto, Imágenes, Audio, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vertexai\n",
    "from vertexai.generative_models import GenerativeModel, Part\n",
    "\n",
    "def generate_video_description(project_id, location, model_name, video_file_uri, prompt):\n",
    "    vertexai.init(project=project_id, location=location)\n",
    "\n",
    "    model = GenerativeModel(model_name)\n",
    "\n",
    "    video_file = Part.from_uri(video_file_uri, mime_type=\"video/mp4\")\n",
    "\n",
    "    contents = [video_file, prompt]\n",
    "\n",
    "    response = model.generate_content(contents)\n",
    "    return response.text\n",
    "\n",
    "# Configuramos los parametros de la API para que funcione con nuestro proyecto de Google Cloud\n",
    "project_id = \"prj-uc-genai-labs\"\n",
    "location = \"us-central1\"\n",
    "\n",
    "# Configuramos los parametros del modelo y el tipo de input que le entregarémos.\n",
    "model_name = \"gemini-1.5-pro-preview-0409\"\n",
    "video_file_uri = \"gs://workshop_pablo_24/0424.mp4\"\n",
    "prompt = \"\"\"\n",
    "  Provide a description of the video.\n",
    "  The description should also contain anything important which people say in the video.\n",
    "\"\"\"\n",
    "\n",
    "description = generate_video_description(project_id, location, model_name, video_file_uri, prompt)\n",
    "\n",
    "# Pequeño Debug para ver que nos está devolviendo la API\n",
    "print(description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que tenemos configurado Google Cloud, Vertex AI, el Modelo y sus Parámetros, querémos interactuar con la API de trello para que Gemini pueda gestionar los tickets. Para esto debemos\n",
    "\n",
    "1. Crear una cuenta de Trello en https://www.trello.com\n",
    "2. Creamos un Power App, una especie de conector entre un tablero de trello y su API\n",
    "3. Generámos y copiamos la API Key para interactuar con la plataforma sin credenciales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta función podrá ser llamada por el modelo utilizando xxxxxxx\n",
    "def create_trello_card(name, due, start):\n",
    "    import requests\n",
    "    import json\n",
    "\n",
    "    url = \"https://api.trello.com/1/cards\"\n",
    "\n",
    "    headers = {\"Accept\": \"application/json\"}\n",
    "\n",
    "    query = {\n",
    "        \"idList\": \"662a0837e895ddb3063a6277\", # Reemplazar por valores propios\n",
    "        \"key\": \"28c3d510ab4b942cf31f2993d4059942\", # Reemplazar por valores propios\n",
    "        \"token\": \"ATTAf9894d9fcfa1a44dd9653a65f141f58e7503c196515909dd2eea97fe41b3ed43D5A5A316\", # Reemplazar por valores propios\n",
    "        \"name\": name,\n",
    "        \"due\": due,\n",
    "        \"start\": start,\n",
    "    }\n",
    "\n",
    "    response = requests.request(\"POST\", url, headers=headers, params=query)\n",
    "\n",
    "    print(\n",
    "        json.dumps(\n",
    "            json.loads(response.text), sort_keys=True, indent=4, separators=(\",\", \": \")\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos el modelo Pydantic #QUE NOS PERMITIRÁ.............."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional\n",
    "from datetime import datetime\n",
    "\n",
    "class CreateTrelloCard(BaseModel):\n",
    "    \"\"\"\n",
    "    Function that calls the Trello API to create a new card.\n",
    "    \n",
    "    \"\"\"\n",
    "    name: str = Field(..., description=\"Name of the card\")\n",
    "    due: Optional[datetime] = Field(...,description=\"Name of the card\")\n",
    "    start: Optional[datetime] = Field(...,description=\"Name of the card\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establecemos una connexión entre Langchain y el Chat de Vertex AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_vertexai import ChatVertexAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [CreateTrelloCard]\n",
    "llm = ChatVertexAI(\n",
    "    model=\"gemini-1.5-pro-preview-0409\",\n",
    "    credentials=credentials,\n",
    "    project_id=\"prj-uc-genai-labs\",\n",
    "    location=\"us-central1\",\n",
    ")\n",
    "\n",
    "\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
