{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook 1: Trabajas en una compañía en el departamento de soporte TI. Ya llevas varios años y te das cuenta de que el trabajo es repetitivo y los usuarios suelen cometer los mismo errores. Con el tiempo el trabajo se va volviendo muy fácil y estás buscando como hacerlo más interesante de acuerdo a tus habilidades.\n",
    "\n",
    "Has pensado en utilizar tus conocimientos avanzados en Python y las sofisticadas herrarmientas de Inteligencia Artifical de Google para automatizar tu trabajo! En especial la plataforma de tickets (Trello).\n",
    "\n",
    "Objetivo: Crear una solución que tome los videos de los problemas de los usuarios, cree, resuma, etiquete y gestione targetas en Trello (Herramienta de tickets de desarrollo y soporte) automáticamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instalamos dependencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade --quiet google-cloud-discoveryengine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podemos explicar para que se instala esto?\n",
    "!pip install google-api-python-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalamos paquetes para conectarnos a los servicios de Google\n",
    "!pip install google-auth\n",
    "!pip install google-auth-oauthlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalamos Vertex AI (Plataforma de desarrollo de soluciones de AI Generativa).\n",
    "# Con esta plataforma podremos acceder a los differentes modelos de Gemini de Google y a otros servicios de Agentes y Chat.\n",
    "!pip install vertexai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalarémos un paquete para que Langchain interactue con Google Vertex AI\n",
    "!pip install langchain-core\n",
    "!pip install -qU langchain-google-vertexai\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mencionar de donde se saca la service account y su paso a paso\n",
    "Importamos las librerías de Google que instalamos previamente, y configuramos las credenciales de Google para autenticarnos con Google Cloud Platform a través de una cuenta de servicio.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.oauth2 import service_account\n",
    "\n",
    "# Path to your service account key file\n",
    "SERVICE_ACCOUNT_FILE = \"prj-uc-genai-labs-8859d31dca67.json\"\n",
    "\n",
    "# Define the scopes\n",
    "SCOPES = [\"https://www.googleapis.com/auth/cloud-platform\"]\n",
    "\n",
    "# Authenticate and construct service\n",
    "credentials = service_account.Credentials.from_service_account_file(\n",
    "        SERVICE_ACCOUNT_FILE, scopes=SCOPES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos Vertex AI, y desde Vertex AI obtenemos los constructores de las clases GenerativeModel y Part, que nos permitiran interactuar fácilmente con la API y diferentes tipos de formatos con los que podremos interactuar con el modelo (Texto, Imágenes, Audio, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crear storage bucket y subir archivo de video a Storage Bucket. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tener cuidado de indicar el project_id correcto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vertexai\n",
    "from vertexai.generative_models import GenerativeModel, Part\n",
    "\n",
    "def generate_video_description(project_id, location, model_name, video_file_uri, prompt):\n",
    "    vertexai.init(project=project_id, location=location)\n",
    "\n",
    "    model = GenerativeModel(model_name)\n",
    "\n",
    "    video_file = Part.from_uri(video_file_uri, mime_type=\"video/mov\")\n",
    "\n",
    "    contents = [video_file, prompt]\n",
    "\n",
    "    response = model.generate_content(contents)\n",
    "    return response.text\n",
    "\n",
    "# Configuramos los parametros de la API para que funcione con nuestro proyecto de Google Cloud\n",
    "project_id = \"prj-uc-genai-labs\"\n",
    "location = \"us-central1\"\n",
    "\n",
    "# Configuramos los parametros del modelo y el tipo de input que le entregarémos.\n",
    "model_name = \"gemini-1.5-pro-preview-0409\"\n",
    "video_file_uri = (\n",
    "    \"gs://workshop-bucket-elgueta-2024/Screen Recording 2024-04-26 at 14.35.40.mov\"\n",
    ")\n",
    "prompt = \"\"\"\n",
    "  Provide a description of the video.\n",
    "  The description should also contain anything important which people say in the video.\n",
    "  Output a json with this schema:\n",
    "  {\n",
    "    \"description\": \"The description of the problem the user is facing\",\n",
    "    }\n",
    "\"\"\"\n",
    "\n",
    "description = generate_video_description(project_id, location, model_name, video_file_uri, prompt)\n",
    "\n",
    "# Pequeño Debug para ver que nos está devolviendo la API\n",
    "print(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_google_vertexai import ChatVertexAI\n",
    "\n",
    "# Configuramos los parametros de la API para que funcione con nuestro proyecto de Google Cloud\n",
    "project_id = \"prj-uc-genai-labs\"\n",
    "location = \"us-central1\"\n",
    "\n",
    "# Configuramos los parametros del modelo y el tipo de input que le entregarémos.\n",
    "model_name = \"gemini-1.5-pro-preview-0409\"\n",
    "video_file_uri = \"gs://workshop-bucket-elgueta-2024/0424.mp4\"\n",
    "\n",
    "# Define the text message with the formatted prompt\n",
    "text_message = {\n",
    "    \"type\": \"text\",\n",
    "    \"text\": \"\"\" Provide a description of the video.\n",
    "  The description should also contain anything important which people say in the video.\"\"\",\n",
    "}\n",
    "image_message = {\"type\": \"media\", \"mimeType\": \"video/mp4\", \"video_url\": video_file_uri}\n",
    "message = HumanMessage(content=[text_message, image_message])\n",
    "llm = ChatVertexAI(model_name=model_name)\n",
    "\n",
    "# Invoke the API client with the message\n",
    "output = llm.invoke([prompt])\n",
    "response = output.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que tenemos configurado Google Cloud, Vertex AI, el Modelo y sus Parámetros, querémos interactuar con la API de trello para que Gemini pueda gestionar los tickets. Para esto debemos\n",
    "\n",
    "1. Crear una cuenta de Trello en https://www.trello.com\n",
    "2. Creamos un Power App, una especie de conector entre un tablero de trello y su API\n",
    "3. Generámos y copiamos la API Key para interactuar con la plataforma sin credenciales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta función podrá ser llamada por el modelo utilizando xxxxxxx\n",
    "def create_trello_card(name, due, start):\n",
    "    import requests\n",
    "    import json\n",
    "\n",
    "    url = \"https://api.trello.com/1/cards\"\n",
    "\n",
    "    headers = {\"Accept\": \"application/json\"}\n",
    "\n",
    "    query = {\n",
    "        \"idList\": \"662a0837e895ddb3063a6277\", # Reemplazar por valores propios\n",
    "        \"key\": \"28c3d510ab4b942cf31f2993d4059942\", # Reemplazar por valores propios\n",
    "        \"token\": \"ATTAf9894d9fcfa1a44dd9653a65f141f58e7503c196515909dd2eea97fe41b3ed43D5A5A316\", # Reemplazar por valores propios\n",
    "        \"name\": name,\n",
    "        \"due\": due,\n",
    "        \"start\": start,\n",
    "    }\n",
    "\n",
    "    response = requests.request(\"POST\", url, headers=headers, params=query)\n",
    "\n",
    "    print(\n",
    "        json.dumps(\n",
    "            json.loads(response.text), sort_keys=True, indent=4, separators=(\",\", \": \")\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos el modelo Pydantic #QUE NOS PERMITIRÁ.............."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional\n",
    "from datetime import datetime\n",
    "from langchain_community.retrievers import (\n",
    "    GoogleVertexAISearchRetriever,\n",
    ")\n",
    "\n",
    "class CreateTrelloCardandAnswer(BaseModel):\n",
    "    \"\"\"\n",
    "    Function that calls the Trello API to create a new card.\n",
    "    \n",
    "    \"\"\"\n",
    "    name: str = Field(..., description=\"Short description of the user problem\")\n",
    "    due: Optional[datetime] = Field(...,description=\"Name of the card\")\n",
    "    start: Optional[datetime] = Field(...,description=\"Name of the card\")\n",
    "    query: str = Field(..., description=\"Query to search\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_from_search(query):\n",
    "\n",
    "    PROJECT_ID = project_id  # Set to your Project ID\n",
    "    LOCATION_ID = \"global\"  # Set to your data store location\n",
    "    DATA_STORE_ID = \"workshop-datastore_1714130543853\"  # Set to your data store ID\n",
    "    retriever = GoogleVertexAISearchRetriever(\n",
    "        project_id=PROJECT_ID,\n",
    "        location_id=LOCATION_ID,\n",
    "        data_store_id=DATA_STORE_ID,\n",
    "        max_documents=3,\n",
    "        engine_data_type=1,\n",
    "    )\n",
    "    result = retriever.invoke(query)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establecemos una connexión entre Langchain y el Chat de Vertex AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_vertexai import ChatVertexAI\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_prompt = \"\"\"\n",
    "Output json. Call the Trello Tool to create a new ticket and the RetrieveSearch to find the answer.\n",
    "User input: {input}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [CreateTrelloCardandAnswer]\n",
    "llm = ChatVertexAI(\n",
    "    model=\"gemini-1.5-pro-preview-0409\",\n",
    "    credentials=credentials,\n",
    "    project_id=\"prj-uc-genai-labs\",\n",
    "    location=\"us-central1\",\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(initial_prompt)\n",
    "\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "chain = prompt | llm_with_tools\n",
    "\n",
    "result = chain.invoke({\"input\": description})\n",
    "\n",
    "print(result.additional_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos el Search Engine en Google Cloud Console:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autenticamos en Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages.base import message_to_dict\n",
    "import json\n",
    "\n",
    "response_dict = message_to_dict(result)\n",
    "function_call = response_dict.get(\"data\", {}).get(\"additional_kwargs\", {}).get(\"function_call\", {})\n",
    "\n",
    "\n",
    "# Assuming 'arguments' is a JSON string, we need to parse it\n",
    "arguments_str = function_call.get(\"arguments\", \"{}\")  # Default to empty JSON object if not found\n",
    "try:\n",
    "    arguments = json.loads(arguments_str)  # Attempt to parse the string as JSON\n",
    "except json.JSONDecodeError:\n",
    "    arguments = {}  # If parsing fails, default to an empty dictionary\n",
    "\n",
    "\n",
    "if function_call.get(\"name\") == \"CreateTrelloCardandAnswer\":\n",
    "    print(type(arguments))  # This should now be 'dict' if the JSON was parsed successfully\n",
    "    create_trello_card(\n",
    "        name=arguments.get(\"name\"),\n",
    "        due=arguments.get(\"due\"),\n",
    "        start=arguments.get(\"start\"),\n",
    "    )\n",
    "    answer = retrieve_from_search(arguments.get(\"query\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_prompt = \"\"\"\n",
    "Based on the user input, and the content retrieved from the search engine, output a response that resolves the user problem.\n",
    "User input: {input}\n",
    "Search result: {search_result}\n",
    "\"\"\"\n",
    "llm = ChatVertexAI(\n",
    "    model=\"gemini-1.5-pro-preview-0409\",\n",
    "    credentials=credentials,\n",
    "    project_id=\"prj-uc-genai-labs\",\n",
    "    location=\"us-central1\",\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(initial_prompt)\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "result = chain.invoke({\"input\": description, \"search_result\": answer})\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
