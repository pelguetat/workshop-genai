{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEqbX8OhE8y9",
        "tags": []
      },
      "source": [
        "# Introducción a Vertex AI Gemini API & Python SDK"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkHPv2myT2cx"
      },
      "source": [
        "## Información General\n",
        "\n",
        "### Gemini\n",
        "\n",
        "Gemini es una familia de modelos de IA generativa desarrollados por Google DeepMind que está diseñada para casos de uso multimodal. La API de Gemini te da acceso a los modelos Gemini Pro y Gemini Pro Vision.\n",
        "\n",
        "### API de Vertex AI Gemini\n",
        "\n",
        "La API de Vertex AI Gemini proporciona una interfaz unificada para interactuar con los modelos Gemini. Hay dos modelos Gemini 1.0 Pro disponibles en la API de Gemini:\n",
        "\n",
        "- **Modelo Gemini 1.0 Pro** (`gemini-1.0-pro`): Diseñado para manejar tareas de lenguaje natural, chat de texto y código de múltiples turnos, y generación de código.\n",
        "- **Modelo Gemini 1.0 Pro Vision** (`gemini-1.0-pro-vision`): Soporta prompts multimodales. Puedes incluir texto, imágenes y video en tus solicitudes de prompts y obtener respuestas de texto o código.\n",
        "- **Modelo Gemini 1.5 Pro** (`gemini-1.5-pro-preview-0409`): Soporta prompts multimodales. Puedes incluir texto, imágenes, video y pdf en tus solicitudes de prompts y obtener respuestas de texto o código.\n",
        "\n",
        "Puedes interactuar con la API de Gemini utilizando los siguientes métodos:\n",
        "#\n",
        "- Usa [Vertex AI Studio](https://cloud.google.com/generative-ai-studio) para pruebas rápidas y generación de comandos\n",
        "- Usa comandos cURL\n",
        "- Usa el SDK de Vertex AI\n",
        "\n",
        "Este cuaderno se centra en usar el **SDK de Vertex AI para Python** para llamar a la API de Vertex AI Gemini.\n",
        "\n",
        "Para más información, consulta la documentación de [IA generativa en Vertex AI](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/overview).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrkcqHrrwMAo"
      },
      "source": [
        "### Objetivos\n",
        "\n",
        "En este tutorial, aprenderás a usar la API de Vertex AI Gemini con el SDK de Vertex AI para Python para interactuar con el modelo Gemini 1.0 Pro (`gemini-1.0-pro`) y el modelo Gemini 1.0 Pro Vision (`gemini-1.0-pro-vision`).\n",
        "\n",
        "Completarás las siguientes tareas:\n",
        "\n",
        "- Instalar el SDK de Vertex AI para Python\n",
        "- Usar la API de Vertex AI Gemini para interactuar con cada modelo\n",
        "  - Modelo Gemini 1.0 Pro (`gemini-1.0-pro`):\n",
        "    - Generar texto a partir de prompts de texto\n",
        "    - Explorar diversas características y opciones de configuración\n",
        "  - Modelo Gemini 1.0 Pro Vision (`gemini-1.0-pro-vision`):\n",
        "    - Generar texto a partir de imágenes y prompts de texto\n",
        "    - Generar texto a partir de video y prompts de texto\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r11Gu7qNgx1p"
      },
      "source": [
        "## Comenzando\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "No17Cw5hgx12"
      },
      "source": [
        "### Instalar Vertex AI SDK para Python\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFy3H3aPgx12",
        "tags": []
      },
      "outputs": [],
      "source": [
        "! pip3 install --upgrade --user google-cloud-aiplatform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5Xep4W9lq-Z"
      },
      "source": [
        "### Reiniciar el entorno de ejecución actual (si están en Jupyter)\n",
        "\n",
        "Para usar los paquetes recién instalados en este entorno de ejecución de Jupyter, debes reiniciar el entorno. Puedes hacerlo ejecutando la celda a continuación, lo que reiniciará el kernel actual.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XRvKdaPDTznN",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Reinicia el kernel después de la instalación para que el entorno pueda acceder a los nuevos packetes.\n",
        "import IPython\n",
        "\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmWOrTJ3gx13"
      },
      "source": [
        "### Autenticate (solo Colab)\n",
        "\n",
        "Si estás ejecutando este cuaderno en Google Colab, ejecuta la siguiente celda para autenticar tu entorno. Este paso no es necesario si estás utilizando [Vertex AI Workbench](https://cloud.google.com/vertex-ai-workbench).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NyKGtVQjgx13",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "# Autenticación adicional es requerida para Google Colab\n",
        "if \"google.colab\" in sys.modules:\n",
        "    # Autentica el usuario en Google Cloud\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DF4l8DTdWgPY"
      },
      "source": [
        "### Establecer la información del proyecto de Google Cloud e inicializar el SDK de Vertex AI\n",
        "\n",
        "Para comenzar a usar Vertex AI, debes tener un proyecto de Google Cloud existente y [habilitar la API de Vertex AI](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com).\n",
        "\n",
        "Aprende más sobre [cómo configurar un proyecto y un entorno de desarrollo](https://cloud.google.com/vertex-ai/docs/start/cloud-environment).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Nqwi-5ufWp_B",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Define la información del proyecto\n",
        "PROJECT_ID = \"prj-uc-genai-labs\"  # @param {type:\"string\"}\n",
        "LOCATION = \"us-central1\"  # @param {type:\"string\"}\n",
        "\n",
        "# Inicializar Vertex AI\n",
        "import vertexai\n",
        "\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXHfaVS66_01"
      },
      "source": [
        "### Importar librerías\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "lslYAvw37JGQ",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from vertexai.generative_models import GenerationConfig, GenerativeModel, Image, Part"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4437b7608c8e"
      },
      "source": [
        "## Utilizar el modelo Gemini 1.0 Pro\n",
        "\n",
        "El modelo Gemini 1.0 Pro (`gemini-1.0-pro`) está diseñado para manejar tareas de lenguaje natural, chat de texto y código de múltiples turnos, y generación de código.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BY1nfXrqRxVX"
      },
      "source": [
        "### Cargar el modelo Gemini 1.0 Pro\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2998506fe6d1",
        "tags": []
      },
      "outputs": [],
      "source": [
        "model = GenerativeModel(\"gemini-1.0-pro\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIl7R_jBUsaC"
      },
      "source": [
        "Generar texto a partir de prompts de texto\n",
        "\n",
        "Envía una prompt de texto al modelo. El modelo Gemini 1.0 Pro (`gemini-1.0-pro`) proporciona un mecanismo de streaming. Con este modo, no necesitas esperar la respuesta completa; puedes comenzar a procesar fragmentos tan pronto como estén accesibles.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eAo-UsfZECGF",
        "tags": []
      },
      "outputs": [],
      "source": [
        "responses = model.generate_content(\"Por qué es el cielo azul?\", stream=True)\n",
        "\n",
        "for response in responses:\n",
        "    print(response.text, end=\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Us8idXnVyQ97"
      },
      "source": [
        "#### Prueba tus propios prompts\n",
        "\n",
        "- ¿Cuáles son los mayores desafíos que enfrenta la industria de la salud?\n",
        "- ¿Cuáles son los últimos desarrollos en la industria automotriz?\n",
        "- ¿Cuáles son las mayores oportunidades en la industria minorista?\n",
        "- (¡Prueba tus propios prompts!)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MmAZQW1GyQ97",
        "tags": []
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"Crea una lista numerada de 10 elementos. Cada elemento en la lista debe ser una tendencia en la industria tecnológica.\n",
        "\n",
        "Cada tendencia debe ser de menos de 5 palabras.\"\"\"  # intenta tu propio prompt\n",
        "\n",
        "responses = model.generate_content(prompt, stream=True)\n",
        "\n",
        "for response in responses:\n",
        "    print(response.text, end=\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDK4XLdz3Oqv"
      },
      "source": [
        "#### Parámetros del modelo\n",
        "\n",
        "Cada prompt que envías al modelo incluye valores de parámetros que controlan cómo el modelo genera una respuesta. El modelo puede generar diferentes resultados para diferentes valores de parámetros. Puedes experimentar con diferentes parámetros del modelo para ver cómo cambian los resultados.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s_2ann-F3WTo",
        "tags": []
      },
      "outputs": [],
      "source": [
        "generation_config = GenerationConfig(\n",
        "    temperature=0.9,\n",
        "    top_p=1.0,\n",
        "    top_k=32,\n",
        "    candidate_count=1,\n",
        "    max_output_tokens=8192,\n",
        ")\n",
        "\n",
        "responses = model.generate_content(\n",
        "    \"Por qué es el cielo azul?\",\n",
        "    generation_config=generation_config,\n",
        "    stream=True,\n",
        ")\n",
        "\n",
        "for response in responses:\n",
        "    print(response.text, end=\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ga0xM9z9fAnR"
      },
      "source": [
        "### Pruebas de prompts de chat\n",
        "\n",
        "El modelo Gemini 1.0 Pro soporta conversaciones naturales de múltiples turnos y es ideal para tareas de texto que requieren interacciones de ida y vuelta. Los siguientes ejemplos muestran cómo responde el modelo durante una conversación de múltiples turnos.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SFbGVflTfBBk",
        "tags": []
      },
      "outputs": [],
      "source": [
        "chat = model.start_chat()\n",
        "\n",
        "prompt = \"\"\"Mi nombre es Pablo. Eres mi asistente personal. Mis películas favoritas son El Señor de los Anillos y El Hobbit.\n",
        "\n",
        "Sugiere otra película que podría gustarme.\n",
        "\"\"\"\n",
        "\n",
        "responses = chat.send_message(prompt, stream=True)\n",
        "\n",
        "for response in responses:\n",
        "    print(response.text, end=\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZP_z_Oh1J4nk"
      },
      "source": [
        "Este prompt de seguimiento muestra cómo responde el modelo basado en el prompt anterior:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OCq7JNBKJrI8",
        "tags": []
      },
      "outputs": [],
      "source": [
        "prompt = \"¿Mis películas favoritas están basadas en una serie de libros?\"\n",
        "responses = chat.send_message(prompt, stream=True)\n",
        "\n",
        "for response in responses:\n",
        "    print(response.text, end=\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kH94T01Oxg-"
      },
      "source": [
        "También puedes ver el historial de chat:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZV9PjJJLOxg-",
        "tags": []
      },
      "outputs": [],
      "source": [
        "print(chat.history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OK6TsnYghrQk"
      },
      "source": [
        "## Usando el modelo Gemini 1.0 Pro Vision\n",
        "\n",
        "Gemini 1.0 Pro Vision (`gemini-1.0-pro-vision`) es un modelo multimodal que soporta prompts multimodales. Puedes incluir texto, imagenes y video en tus prompts y obtener respuestas de texto o código.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTMywdzUORIA"
      },
      "source": [
        "### Cargar el modelo Gemini 1.0 Pro Vision\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "lRyTw2iPhEXG",
        "tags": []
      },
      "outputs": [],
      "source": [
        "multimodal_model = GenerativeModel(\"gemini-1.0-pro-vision\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwvfMDEDVyKI"
      },
      "source": [
        "### Definir funciones de ayuda\n",
        "\n",
        "Definir funciones de ayuda para cargar y mostrar imágenes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "NQS13DI6Pjp6",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import http.client\n",
        "import typing\n",
        "import urllib.request\n",
        "\n",
        "import IPython.display\n",
        "from PIL import Image as PIL_Image\n",
        "from PIL import ImageOps as PIL_ImageOps\n",
        "\n",
        "\n",
        "def display_images(\n",
        "    images: typing.Iterable[Image],\n",
        "    max_width: int = 600,\n",
        "    max_height: int = 350,\n",
        ") -> None:\n",
        "    for image in images:\n",
        "        pil_image = typing.cast(PIL_Image.Image, image._pil_image)\n",
        "        if pil_image.mode != \"RGB\":\n",
        "            # RGB es soportado por todos los entornos Jupyter (e.g. RGBA no todavía)\n",
        "            pil_image = pil_image.convert(\"RGB\")\n",
        "        image_width, image_height = pil_image.size\n",
        "        if max_width < image_width or max_height < image_height:\n",
        "            # Reduce el tamaño para mostrarla más pequeña\n",
        "            pil_image = PIL_ImageOps.contain(pil_image, (max_width, max_height))\n",
        "        IPython.display.display(pil_image)\n",
        "\n",
        "\n",
        "def get_image_bytes_from_url(image_url: str) -> bytes:\n",
        "    with urllib.request.urlopen(image_url) as response:\n",
        "        response = typing.cast(http.client.HTTPResponse, response)\n",
        "        image_bytes = response.read()\n",
        "    return image_bytes\n",
        "\n",
        "\n",
        "def load_image_from_url(image_url: str) -> Image:\n",
        "    image_bytes = get_image_bytes_from_url(image_url)\n",
        "    return Image.from_bytes(image_bytes)\n",
        "\n",
        "\n",
        "def get_url_from_gcs(gcs_uri: str) -> str:\n",
        "    # convierte gcs uri a url para mostrar la imagen.\n",
        "    url = \"https://storage.googleapis.com/\" + gcs_uri.replace(\"gs://\", \"\").replace(\n",
        "        \" \", \"%20\"\n",
        "    )\n",
        "    return url\n",
        "\n",
        "\n",
        "def print_multimodal_prompt(contents: list):\n",
        "    \"\"\"\n",
        "    Given contents that would be sent to Gemini,\n",
        "    output the full multimodal prompt for ease of readability.\n",
        "    \"\"\"\n",
        "    for content in contents:\n",
        "        if isinstance(content, Image):\n",
        "            display_images([content])\n",
        "        elif isinstance(content, Part):\n",
        "            url = get_url_from_gcs(content.file_data.file_uri)\n",
        "            IPython.display.display(load_image_from_url(url))\n",
        "        else:\n",
        "            print(content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wy75sLb-yjNn"
      },
      "source": [
        "Generar texto a partir de imagen local y texto\n",
        "\n",
        "Utiliza el método `Image.load_from_file` para cargar un archivo local como la imagen para generar texto.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KzqjpEiryjNo",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Descarga una imagen de Google Cloud Storage\n",
        "! gsutil cp \"gs://cloud-samples-data/generative-ai/image/320px-Felis_catus-cat_on_snow.jpg\" ./image.jpg\n",
        "\n",
        "# Cargala de un archivo local\n",
        "image = Image.load_from_file(\"image.jpg\")\n",
        "\n",
        "# Prepara el contenido\n",
        "prompt = \"Describe esta imagen?\"\n",
        "contents = [image, prompt]\n",
        "\n",
        "responses = multimodal_model.generate_content(contents, stream=True)\n",
        "\n",
        "print(\"-------Prompt--------\")\n",
        "print_multimodal_prompt(contents)\n",
        "\n",
        "print(\"\\n-------Response--------\")\n",
        "for response in responses:\n",
        "    print(response.text, end=\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCmdIFfHOxhF"
      },
      "source": [
        "Generar texto a partir de texto e imagen(es)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJvME8gV2nyk"
      },
      "source": [
        "#### Imágenes con URIs de Cloud Storage\n",
        "\n",
        "Si tus imágenes están almacenadas en [Cloud Storage](https://cloud.google.com/storage/docs), puedes especificar el URI de Cloud Storage de la imagen para incluirla en el prompt. También debes especificar el campo `mime_type`. Los tipos MIME soportados para imágenes incluyen `image/png` y `image/jpeg`.\n",
        "\n",
        "Nota que el URI (no confundir con URL) para un objeto de Cloud Storage siempre debe comenzar con `gs://`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-5T1whb5OxhF",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Carga una imagen desde Cloud Storage URI\n",
        "gcs_uri = \"gs://cloud-samples-data/generative-ai/image/boats.jpeg\"\n",
        "\n",
        "# Prepara el contenido\n",
        "image = Part.from_uri(gcs_uri, mime_type=\"image/jpeg\")\n",
        "prompt = \"Describe esta escena?\"\n",
        "contents = [image, prompt]\n",
        "\n",
        "responses = multimodal_model.generate_content(contents, stream=True)\n",
        "\n",
        "print(\"-------Prompt--------\")\n",
        "print_multimodal_prompt(contents)\n",
        "\n",
        "print(\"\\n-------Response--------\")\n",
        "for response in responses:\n",
        "    print(response.text, end=\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mt6zNb0_OxhF"
      },
      "source": [
        "Imágenes con links\n",
        "\n",
        "También puedes utilizar links a imágenes, como se muestra a continuación. La función de ayuda `load_image_from_url()` (que se declaró anteriormente) convierte la imagen a bytes y la devuelve como un objeto Image que luego puede enviarse a Gemini 1.0 Pro Vision junto con el texto del prompt.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PQRlfXp9OxhF",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Carga una imagen desde Cloud Storage URI\n",
        "image_url = (\n",
        "    \"https://storage.googleapis.com/cloud-samples-data/generative-ai/image/boats.jpeg\" # En este caso el bucket es público\n",
        ")\n",
        "image = load_image_from_url(image_url)  # convert to bytes\n",
        "\n",
        "# Prepara el contenido\n",
        "prompt = \"Describe la escena\"\n",
        "contents = [image, prompt]\n",
        "\n",
        "responses = multimodal_model.generate_content(contents, stream=True)\n",
        "\n",
        "print(\"-------Prompt--------\")\n",
        "print_multimodal_prompt(contents)\n",
        "\n",
        "print(\"\\n-------Response--------\")\n",
        "for response in responses:\n",
        "    print(response.text, end=\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOvDkR1gOxhF"
      },
      "source": [
        "#### Combinando múltiples imágenes y textos en el prompt para hacer few-shot prompting\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "repKenaaOxhF"
      },
      "source": [
        "Puedes enviar más de una imagen a la vez, y también colocar tus imágenes en cualquier lugar junto a tu texto de prompt.\n",
        "\n",
        "En el ejemplo a continuación, se realiza un prompting de few-shot para que Gemini 1.0 Pro Vision devuelva la ciudad y el monumento en un formato JSON específico.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VfU7Qlz1hAEA",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Carga imagenes desde Cloud Storage URI\n",
        "image1_url = \"https://storage.googleapis.com/github-repo/img/gemini/intro/landmark1.jpg\"\n",
        "image2_url = \"https://storage.googleapis.com/github-repo/img/gemini/intro/landmark2.jpg\"\n",
        "image3_url = \"https://storage.googleapis.com/github-repo/img/gemini/intro/landmark3.jpg\"\n",
        "image1 = load_image_from_url(image1_url)\n",
        "image2 = load_image_from_url(image2_url)\n",
        "image3 = load_image_from_url(image3_url)\n",
        "\n",
        "# Prepara los prompts\n",
        "prompt1 = \"\"\"{\"city\": \"London\", \"Landmark:\", \"Big Ben\"}\"\"\"\n",
        "prompt2 = \"\"\"{\"city\": \"Paris\", \"Landmark:\", \"Eiffel Tower\"}\"\"\"\n",
        "\n",
        "# Prepara el contenido\n",
        "contents = [image1, prompt1, image2, prompt2, image3]\n",
        "\n",
        "responses = multimodal_model.generate_content(contents, stream=True)\n",
        "\n",
        "print(\"-------Prompt--------\")\n",
        "print_multimodal_prompt(contents)\n",
        "\n",
        "print(\"\\n-------Response--------\")\n",
        "for response in responses:\n",
        "    print(response.text, end=\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyjpi1fB7mgj"
      },
      "source": [
        "Generar texto a partir de un archivo de video\n",
        "\n",
        "Especifica el URI de Cloud Storage del video para incluirlo en el prompt. El bucket que almacena el archivo debe estar en el mismo proyecto de Google Cloud que envía la solicitud. También debes especificar el campo `mime_type`. El tipo MIME soportado para video incluye `video/mp4`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MIZw4NZgOxhG",
        "tags": []
      },
      "outputs": [],
      "source": [
        "file_path = \"github-repo/img/gemini/multimodality_usecases_overview/pixel8.mp4\"\n",
        "video_uri = f\"gs://{file_path}\"\n",
        "video_url = f\"https://storage.googleapis.com/{file_path}\"\n",
        "\n",
        "IPython.display.Video(video_url, width=450)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VXX1jLXq7ojB",
        "tags": []
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"\n",
        "Responde las siguientes preguntas usando únicamente el video:\n",
        "¿Cuál es la profesión de la persona principal?\n",
        "¿Cuáles son las características principales del teléfono destacadas?\n",
        "¿En qué ciudad se grabó esto?\n",
        "Proporciona la respuesta en JSON.\n",
        "\"\"\"\n",
        "\n",
        "video = Part.from_uri(video_uri, mime_type=\"video/mp4\")\n",
        "contents = [prompt, video]\n",
        "\n",
        "responses = multimodal_model.generate_content(contents, stream=True)\n",
        "\n",
        "for response in responses:\n",
        "    print(response.text, end=\"\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W147g42rWkR2"
      },
      "execution_count": 18,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "environment": {
      "kernel": "conda-root-py",
      "name": "workbench-notebooks.m115",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m115"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel) (Local)",
      "language": "python",
      "name": "conda-root-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}